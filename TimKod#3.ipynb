{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import random as random\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file):\n",
    "    return open(file).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "#ZADANIE 1\n",
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entropia\n",
    "# MAX - równomierne prawdopodobieństwo wszystkich elementów\n",
    "# 0 - prawdopodobieństwo = 1 (zerowa niepewność)\n",
    "\n",
    "# H(X) = -suma(p_i * log2(p_i))\n",
    "# p_i - prawdopodobieństwo wystąpienia elementu itego\n",
    "\n",
    "\n",
    "#Entropia warunkowa\n",
    "#jak bardzo rozrzucone są litery jeżeli poprzednia jest znana\n",
    "#zależnie od tego ile poprzednich elementów to inny stopień entropii warunkowej\n",
    "#-suma(prawdopodobieństwoWystąpieniaPary * log2(prawdopodobieństwoWystąpieniaWarunkowe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia(probability):\n",
    "    h = 0\n",
    "    for p in probability:\n",
    "        h += p * log(p, 2)\n",
    "    \n",
    "    h = -h\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropia([0.4,0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countChars(text2):\n",
    "    chars = {}\n",
    "    for char in list(text2):\n",
    "        if char in chars:\n",
    "            chars[char] += 1\n",
    "        else:\n",
    "            chars[char] = 1\n",
    "    return chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = readFile(\"norm_wiki_sample.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = readLetters(wikipedia)\n",
    "probability = []\n",
    "for letter in letters:\n",
    "    probability.append(letter / len(wikipedia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2803962467015655"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entropia dla języka angielskiego:\n",
    "entropia(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.209453365628954"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entropia dla przybliżenia zerowego języka angielskiego\n",
    "n = 37\n",
    "prob = [1 / 37] * n\n",
    "entropia(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "angielskiProbka = readFile(\"norm_wiki_en.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = readLetters(angielskiProbka)\n",
    "probability = []\n",
    "for letter in letters:\n",
    "    probability.append(letter / len(angielskiProbka))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.288221453845133"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entropia znakowa dla próbki języka angielskiego:\n",
    "entropia(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-suma(prawdopodobieństwoWystąpieniaPary * log2(prawdopodobieństwoWystąpieniaWarunkowe))\n",
    "def entropiaWaruknowa(prawdopodobienstwoLaczne, prawdopodobienstwoWarunkowe):\n",
    "    h = 0\n",
    "    for pl, pw in zip(prawdopodobienstwoLaczne, prawdopodobienstwoWarunkowe):\n",
    "        h += pl * log(pw, 2)\n",
    "    \n",
    "    h = -h\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policzyć prawdopodobieństwo wystąpienia ciągu znaków rzędu n;\n",
    "#policzyć prawdopodobieństwo wystąpienia każdego znaku po ciągu znaków;\n",
    "#policzyć sumę prawdopodobieństw\n",
    "\n",
    "#powtórzyć dla kazdego ciągu znaków rzędu n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tekst - tekst do przeszukania\n",
    "#l - długość n-gramu\n",
    "\n",
    "\n",
    "#O CO TUTAJ CHODZI\n",
    "#dla entropii warunkowej 1szego rzędu\n",
    "#dzielimy tekst na pary znaków\n",
    "#liczymy prawdopodobieństwo wystąpnienia kazdej pary (np. \"al\")\n",
    "#liczymy prawdopodobieństwo wystąpienia drugiego znaku po pierwszyym (np: \"l\" po \"a\") \n",
    "#(ile razy wystepuje \"al\" / ile razy występuje \"a\")\n",
    "#dla drugiego rzędu trójki\n",
    "#ile razy \"abc\"\n",
    "#ile razy \"c\" po \"ab\"\n",
    "\n",
    "def dzielenieTekstu(tekst, l):\n",
    "    ngrams = {}\n",
    "    \n",
    "    chars = {}\n",
    "    \n",
    "    percent = 0\n",
    "    for i in range(len(tekst) + 1):\n",
    "        if i >= l:\n",
    "            ngram = tekst[i-l:i]\n",
    "            #Zliczanie ngramu:\n",
    "            if ngram in ngrams:\n",
    "                ngrams[ngram] += 1\n",
    "            else:\n",
    "                ngrams[ngram] = 1\n",
    "            #Zliczanie bez ostatniego znaku:\n",
    "            char = ngram[:-1]\n",
    "            #print(ngram, char)\n",
    "            if char in chars:\n",
    "                chars[char] += 1\n",
    "            else:\n",
    "                chars[char] = 1\n",
    "                \n",
    "    return ngrams, chars\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#O CO TUTAJ CHODZI\n",
    "#dla entropii warunkowej 1szego rzędu\n",
    "#dzielimy tekst na pary znaków\n",
    "#liczymy prawdopodobieństwo wystąpnienia kazdej pary (np. \"al\")\n",
    "#liczymy prawdopodobieństwo wystąpienia drugiego znaku po pierwszyym (np: \"l\" po \"a\") \n",
    "#(ile razy wystepuje \"al\" / ile razy występuje \"a\")\n",
    "#dla drugiego rzędu trójki\n",
    "#ile razy \"abc\"\n",
    "#ile razy \"c\" po \"ab\"\n",
    "\n",
    "#tekst - tekst do przeszukania\n",
    "#l - liczba wyrazów\n",
    "def dzielenieTekstuWyrazy(tekst, n):\n",
    "    n_tuples = {}    \n",
    "    n_minus_1_tuples = {}\n",
    "        \n",
    "    percent = 0\n",
    "    sentence = []\n",
    "    \n",
    "    words = tekst.split()\n",
    "        \n",
    "    for i in range(len(words) - (n - 1)):\n",
    "        begin_index = i \n",
    "        end_index = i + n\n",
    "        \n",
    "        n_tuple = words[begin_index:end_index]\n",
    "        \n",
    "        n_tuple_key = \" \".join(n_tuple)\n",
    "        \n",
    "        #Zliczanie ngramu:\n",
    "        if n_tuple_key in n_tuples:\n",
    "            n_tuples[n_tuple_key] += 1\n",
    "        else:\n",
    "            n_tuples[n_tuple_key] = 1\n",
    "            \n",
    "            \n",
    "        n_minus_1_tuple = words[begin_index:end_index - 1]\n",
    "        \n",
    "        n_minus_1_tuple_key = \" \".join(n_minus_1_tuple)\n",
    "        \n",
    "        #Zliczanie ngramu - 1:\n",
    "        if n_minus_1_tuple_key in n_minus_1_tuples:\n",
    "            n_minus_1_tuples[n_minus_1_tuple_key] += 1\n",
    "        else:\n",
    "            n_minus_1_tuples[n_minus_1_tuple_key] = 1\n",
    "\n",
    "                \n",
    "    return n_tuples, n_minus_1_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczPrawdopodobienstwoWarunkoweWyrazow(n_tuples, n_minus_1_tuples):\n",
    "    probability = []\n",
    "    \n",
    "    for ngram, occurences in n_tuples.items():\n",
    "        n_tuple_key = ngram.split()\n",
    "        n_minus_1_tuple = n_tuple_key[:-1]\n",
    "        n_minus_1_tuple_key = \" \".join(n_minus_1_tuple)\n",
    "\n",
    "        probability.append(occurences / n_minus_1_tuples[n_minus_1_tuple_key])\n",
    "\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczPrawdopodobienstwoWystapieniaZdania(n_tuples):\n",
    "    probability = []\n",
    "    occurences_sum = sum(n_tuples.values())\n",
    "    \n",
    "    for ngram, occurences in n_tuples.items():\n",
    "        probability.append(occurences / occurences_sum)\n",
    "        \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczPrawdopodobienstwoWarunkowe(ngrams, chars):\n",
    "    probability = []\n",
    "    \n",
    "    for ngram, occurences in ngrams.items():\n",
    "        char = ngram[:-1]\n",
    "        probability.append(occurences / chars[char])\n",
    "\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczPrawdopodobienstwoWystapieniaNgramu(ngrams):\n",
    "    probability = []\n",
    "    occurences_sum = sum(ngrams.values())\n",
    "    \n",
    "    for ngram, occurences in ngrams.items():\n",
    "        probability.append(occurences / occurences_sum)\n",
    "        \n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWords(text2):\n",
    "    n_tuples = {} \n",
    "    words = text2.split()\n",
    "    \n",
    "    for word in words:\n",
    "        if word in n_tuples:\n",
    "            n_tuples[word] += 1\n",
    "        else:\n",
    "            n_tuples[word] = 1\n",
    "            \n",
    "    return n_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczEntropieSlowna(plik):\n",
    "    counts = countWords(plik)\n",
    "    probability = obliczPrawdopodobienstwoWystapieniaZdania(counts)\n",
    "    \n",
    "    return entropia(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczEntropieZnakowa(plik):\n",
    "    counts = countChars(plik)\n",
    "    probability = obliczPrawdopodobienstwoWystapieniaNgramu(counts)\n",
    "    \n",
    "    return entropia(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczZnakowaEntropieDlaTekstu(tekst, stopien):\n",
    "    ngrams, chars,  = dzielenieTekstu(tekst, stopien + 1)\n",
    "    probability_conditional  = obliczPrawdopodobienstwoWarunkowe(ngrams, chars)\n",
    "    probability = obliczPrawdopodobienstwoWystapieniaNgramu(ngrams)\n",
    "    return entropiaWaruknowa(probability, probability_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obliczSlownaEntropieDlaTekstu(tekst, stopien):\n",
    "    ngrams, chars = dzielenieTekstuWyrazy(tekst, stopien + 1)\n",
    "    probability_conditional  = obliczPrawdopodobienstwoWarunkoweWyrazow(ngrams, chars)\n",
    "    probability = obliczPrawdopodobienstwoWystapieniaZdania(ngrams)\n",
    "    return entropiaWaruknowa(probability, probability_conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm_wiki_en.txt',\n",
       " 'norm_wiki_la.txt',\n",
       " 'sample0.txt',\n",
       " 'sample1.txt',\n",
       " 'sample2.txt',\n",
       " 'sample3.txt',\n",
       " 'sample4.txt',\n",
       " 'sample5.txt']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nazwy_plikow = [\n",
    "    \"norm_wiki_en.txt\",\n",
    "    \"norm_wiki_la.txt\",\n",
    "    \"sample0.txt\",\n",
    "    \"sample1.txt\",\n",
    "    \"sample2.txt\",\n",
    "    \"sample3.txt\",\n",
    "    \"sample4.txt\",\n",
    "    \"sample5.txt\"    \n",
    "]\n",
    "nazwy_plikow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odczytajEntropie(plik):\n",
    "    entropieZnakowe = []\n",
    "    entropieSlowne = []\n",
    "    \n",
    "    entropieZnakowe.append(obliczEntropieZnakowa(plik))\n",
    "    entropieSlowne.append(obliczEntropieSlowna(plik))\n",
    "    \n",
    "    for i in range(4):\n",
    "        entropieZnakowe.append(obliczZnakowaEntropieDlaTekstu(plik, i + 1))\n",
    "        entropieSlowne.append(obliczSlownaEntropieDlaTekstu(plik, i + 1))\n",
    "    return entropieZnakowe, entropieSlowne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_wiki_en.txt\n",
      "[4.288221453845133, 3.5166047989860245, 3.0183191907911358, 2.4815659195766617, 2.0211849323249758]\n",
      "[11.543993773635416, 6.389175065964963, 2.176460456201819, 0.48467886887154094, 0.1096531537240352]\n",
      "-------------\n",
      "norm_wiki_la.txt\n",
      "[4.228247465746813, 3.4501260596144285, 2.823492012531133, 2.1520313374215085, 1.6427637761375666]\n",
      "[11.969194044355133, 4.400025431234719, 1.1668830347273602, 0.3880347336500466, 0.20646821824459533]\n",
      "-------------\n",
      "sample0.txt\n",
      "[4.273001240566633, 2.915894004347894, 2.00035924493487, 1.5392818308881442, 1.4385817627111477]\n",
      "[7.748741386140158, 7.486391705240558, 4.406703462196933, 0.5950087061871917, 0.01206212769881263]\n",
      "-------------\n",
      "sample1.txt\n",
      "[4.127006135549721, 3.239149992123347, 2.8612796847871795, 2.3266847405634032, 1.8135100091144944]\n",
      "[11.500698483659843, 5.372245318605186, 1.5747393031025305, 0.5075112949819727, 0.29345806693802967]\n",
      "-------------\n",
      "sample2.txt\n",
      "[3.993311800232584, 3.050439282781127, 2.467660235741552, 1.939772326144397, 1.7020325739558706]\n",
      "[8.023869815826423, 7.348623166135008, 3.7819360988823183, 0.8595059631118873, 0.08199123582449071]\n",
      "-------------\n",
      "sample3.txt\n",
      "[3.930297834157987, 3.1844670670954263, 2.6278957095513134, 2.0239914888059407, 1.534243355401003]\n",
      "[9.061119324692852, 5.9502208484587875, 2.6308074182196752, 1.264091423924473, 0.41432739497180254]\n",
      "-------------\n",
      "sample4.txt\n",
      "[4.2538095673790135, 4.229101430962362, 4.226828937890913, 4.1785351482827835, 3.7661315160283046]\n",
      "[17.129669110943123, 3.444253112212607, 0.23407601703789896, 0.0032274276117648156, 7.608894145064654e-06]\n",
      "-------------\n",
      "sample5.txt\n",
      "[4.441688018481797, 3.5230981260850296, 3.250620854649217, 2.83427148565169, 2.1724407900562195]\n",
      "[16.50952760746038, -0.0, -0.0, -0.0, -0.0]\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for nazwa_pliku in nazwy_plikow:\n",
    "    plik = readFile(nazwa_pliku);\n",
    "    entropieZnakowe, entropieSlowne = odczytajEntropie(plik)\n",
    "    print(nazwa_pliku)\n",
    "    print(entropieZnakowe)\n",
    "    print(entropieSlowne)\n",
    "    print(\"-------------\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wnioski\n",
    "\n",
    "#sample0 - \n",
    "#sample1 - \n",
    "#sample2 - nie jest to język, entropia warunkowa 3 i 4 stopnia dla wyrazów daje takie same wyniki. \n",
    "#sample3 - \n",
    "#sample4 -\n",
    "#sample5 - nie jest to język"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
